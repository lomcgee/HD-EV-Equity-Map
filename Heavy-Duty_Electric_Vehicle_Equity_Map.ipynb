{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cdb39-8872-4b3c-a5b4-182396600762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "import os\n",
    "import plotly.express as px\n",
    "import json\n",
    "import pyproj\n",
    "import shapely.geometry\n",
    "import h3\n",
    "import plotly.graph_objects as go\n",
    "import logging\n",
    "\n",
    "# Configuring logging settings\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename='EVEQ.log', filemode='w', level=logging.DEBUG)\n",
    "\n",
    "# Suppress debug and info logs from external libraries including fiona and gdal\n",
    "logging.getLogger('gdal').setLevel(logging.WARNING)\n",
    "\n",
    "# Defining path to the .zip file\n",
    "zip_path = 'EJSCREEN_2024_BG_with_AS_CNMI_GU_VI.gdb.zip'\n",
    "\n",
    "# Extract the .zip file\n",
    "extracted_path = 'EJSCREEN_2024_BG_with_AS_CNMI_GU_VI.gdb'\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_path)\n",
    "\n",
    "# Joining path to the extracted .gdb directory\n",
    "gdb_path = os.path.join(extracted_path, 'EJScreen_2024_BG_with_AS_CNMI_GU_VI.gdb')\n",
    "\n",
    "# Loading the full data set layer into a GeoDataFrame\n",
    "layer_name = 'EJSCREEN_Full_with_AS_CNMI_GU_VI' #this geo database has the EJSCREEN data layer and a US map layer\n",
    "gdf = gpd.read_file(gdb_path, layer=layer_name)\n",
    "\n",
    "# Display the first few rows of the GeoDataFrame\n",
    "logger.info(f'First few rows of the GeoDataFrame:\\n{gdf.head(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ade359-e93a-4fe7-959e-1bb5dc15e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create another dataframe to call back on if geometry errors occur\n",
    "gdf1 = gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab722a9-6f5f-4334-81ef-5f2ebd90e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not run this cell unless the below cell returns \"inf\" values for geometry. Then run this cell and rerun conversion cell below\n",
    "gdf = gdf1\n",
    "logger.info(f'{gdf.head(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41fade-4fcf-452d-89c7-a7c0d0152a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to WGS84 to ensure proper coordinates\n",
    "logger.info(f'{gdf.crs}')\n",
    "gdf = gdf.to_crs(epsg=4326) \n",
    "logger.info('Ensure the gdf below has numeric lat/lon coordinates under the geometry column and does not just display \"inf\" repeatedly. If it displays inf, run the cell above and then rerun this cell')\n",
    "logger.info(f'{gdf.head()}') \n",
    "logger.info(f'{gdf.crs}')\n",
    "print(gdf.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfbc86-8c59-4d14-9787-9bc681a0cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing DOE/DOT identified DACs data\n",
    "\n",
    "# Path to the DOE/DOT zip file\n",
    "DOEDOT_zip_path = 'dacs_nevi_joint_May2022.zip'\n",
    "\n",
    "# Extract the .zip file\n",
    "DOEDOT_extracted_path = 'dacs_nevi_joint_May2022'\n",
    "with zipfile.ZipFile(DOEDOT_zip_path, 'r') as DOEDOT_zip:\n",
    "    DOEDOT_zip.extractall(DOEDOT_extracted_path)\n",
    "\n",
    "# Path to the extracted directory\n",
    "DOEDOT_path = os.path.join(DOEDOT_extracted_path, 'dacs_nevi_joint_May2022')\n",
    "\n",
    "DOEDOT_gdf = gpd.read_file(DOEDOT_path)\n",
    "logger.info(f'First few rows of the DOE/DOT GeoDataFrame:\\n{DOEDOT_gdf.head(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9171c-5035-4287-acd3-e6fc74a6b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the type of charging station. PureHDV if only HDV ports will be available. MixedPorts if MDHV and LDV ports available. Leave blank if either of these cases apply.\n",
    "Station_Type = (\"PureHDV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb2a96-cabf-43a9-8fe2-818940a9adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the number of block groups you want to display\n",
    "block_groups = 20\n",
    "logger.info(f'number of block groups {block_groups}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc849a1f-8a2c-44e8-90df-dbc7ecbc9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing station location data into a geodataframe\n",
    "OPT_STA_df = pd.read_csv('stations.csv') # stations.csv is an example of the accepted formatting\n",
    "logger.info(f'Station Location Data:\\n{OPT_STA_df.head(20)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac05ff-6f7b-4799-ae0d-bff28e51b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning station data to just get where stations are to be built\n",
    "\n",
    "#crete empty list to store built stations to\n",
    "Stations = []\n",
    "\n",
    "#Index through the optimal station dataframe, adding rows where built = 1 to station list\n",
    "for index, row in OPT_STA_df.iterrows():\n",
    "    if row[\"built\"] == 1:\n",
    "        Stations.append(row[\"hex\"])\n",
    "logger.info(f'{Stations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175396ce-04f8-40f5-8f9e-ced0b952a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new relative disadvantage columns\n",
    "gdf['Econ_DA'] = gdf[['P_LOWINCPCT', 'P_UNEMPPCT']].mean(axis=1)\n",
    "gdf['Soc_DA'] = gdf[['P_PEOPCOLORPCT', 'P_DISABILITYPCT', 'P_LINGISOPCT', 'P_LESSHSPCT', 'P_OVER64PCT']].mean(axis=1)\n",
    "gdf['Transp_DA'] = gdf[['P_PM25', 'P_OZONE', 'P_DSLPM', 'P_RSEI_AIR', 'P_PTRAF', 'P_NO2']].mean(axis=1)\n",
    "gdf['Env_DA'] = gdf[['P_LIFEEXPPCT', 'P_LDPNT', 'P_PNPL', 'P_PRMP', 'P_PTSDF', 'P_UST', 'P_PWDIS']].mean(axis=1)\n",
    "gdf['DAC_Ind'] = gdf[['Econ_DA', 'Soc_DA', 'Transp_DA', 'Env_DA']].sum(axis=1) / 4\n",
    "\n",
    "# Display the first 10 rows of the updated GeoDataFrame\n",
    "logger.info(f'Updated gdf with DAC Index info:\\n{gdf.head()}')\n",
    "\n",
    "#Note: Null values are not calculated in mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799ee2e-3253-469c-926c-2294419481a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running a for loop over each of erics datapoints to find the nearest block groups to map\n",
    "\n",
    "#Create an empty list to hold the subset from the gdf for each iteration\n",
    "Sub = []\n",
    "#Create empty lists to hold station latitude and longitude\n",
    "Sta_Lat = []\n",
    "Sta_Lon = []\n",
    "    \n",
    "# Re-project the GeoDataFrame to a suitable projected CRS (EPSG:3857) so the Distance function can be used. I think move this out of for loop\n",
    "#print(gdf.crs)\n",
    "gdf_projected1 = gdf.to_crs(epsg=3857)\n",
    "\n",
    "for i in range(len(Stations)):\n",
    "    # First testing ability to make and sort this new column for one point\n",
    "    h = Stations[i]\n",
    "    latlon = h3.h3_to_geo(h)\n",
    "    \n",
    "    # Separating latitude and longitude\n",
    "    lat = latlon[0]\n",
    "    lon = latlon[1]\n",
    "\n",
    "    #Append Sta_Lat list adding lat for point and do same respectively for lon\n",
    "    Sta_Lat.append(lat)\n",
    "    Sta_Lon.append(lon)\n",
    "    \n",
    "    # Define a point with the lat/lon from the optimal charging station location data\n",
    "    point = shapely.geometry.Point(lon, lat)  # Note: input longitude and then latitude\n",
    "    \n",
    "    # Re-project the point to the same projected CRS and extract that point\n",
    "    point_projected = gpd.GeoSeries([point], crs=\"EPSG:4326\").to_crs(epsg=3857).iloc[0]\n",
    "    \n",
    "    # Calculate the distance from the point to each geometry in the re-projected GeoDataFrame\n",
    "    gdf_projected1['Distance'] = gdf_projected1.distance(point_projected)\n",
    "    \n",
    "    # Sort the GeoDataFrame by distance\n",
    "    gdf_sorted = gdf_projected1.sort_values(by='Distance')\n",
    "    \n",
    "    # Create a subset with the desired number of block groups\n",
    "    gdf_sub = gdf_sorted.iloc[0:block_groups].copy()\n",
    "\n",
    "    #Append gdf_subset to sub list holding these gdf subsets\n",
    "    Sub.append(gdf_sub)\n",
    "\n",
    "#Concate the list back into a GeoDataFrame\n",
    "gdf_subset = pd.concat(Sub, ignore_index=True)\n",
    "logger.info(f'First few rows of gdf_subset:\\n{gdf_subset.head(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50693fbb-66c2-4b29-9078-5034b82179cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detects where data was not present for specific indicators and not included in the mean calculation for calculating the DAC_Index\n",
    "\n",
    "for i in range(len(gdf_subset)):\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_LOWINCPCT']):\n",
    "        logger.info(f'Percentile for % low income not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')       \n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_UNEMPPCT']):\n",
    "        logger.info(f'Percentile for % unemployed not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PEOPCOLORPCT']):\n",
    "        logger.info(f'Percentile for % people of color not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_DISABILITYPCT']):\n",
    "        logger.info(f'Percentile for % persons with disabilities not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_LINGISOPCT']):\n",
    "        logger.info(f'Percentile for % limited English speaking not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_LESSHSPCT']):\n",
    "        logger.info(f'Percentile for % less than high school education not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_OVER64PCT']):\n",
    "        logger.info(f'Percentile for % over age 64 not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PM25']):\n",
    "        logger.info(f'Percentile for Particulate Matter 2.5 not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_OZONE']):\n",
    "        logger.info(f'Percentile for ozone not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_DSLPM']):\n",
    "        logger.info(f'Percentile for diesel particulate matter not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_RSEI_AIR']):\n",
    "        logger.info(f'Percentile for toxic releases to air not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PTRAF']):\n",
    "        logger.info(f'Percentile for traffic proximity not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_NO2']):\n",
    "        logger.info(f'Percentile for nitrogen dioxide (NO2) not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_LIFEEXPPCT']):\n",
    "        logger.info(f'Percentile for low life expectancy not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_LDPNT']):\n",
    "        logger.info(f'Percentile for lead paint not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PNPL']):\n",
    "        logger.info(f'Percentile for superfund proximity not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PRMP']):\n",
    "        logger.info(f'Percentile for RMP facility proximity not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PTSDF']):\n",
    "        logger.info(f'Percentile for hazardous waste proximity not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_UST']):\n",
    "        logger.info(f'Percentile for underground storage tanks not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')\n",
    "    if pd.isnull(gdf_subset.loc[i, 'P_PWDIS']):\n",
    "        logger.info(f'Percentile for wastewater discharge not included in calculated mean in block group: {gdf_subset.loc[i, \"ID\"]}, {gdf_subset.loc[i, \"ST_ABBREV\"]}, {gdf_subset.loc[i, \"CNTY_NAME\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f904f0-0d18-4544-ac9c-a10c296d5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell creates a plotly map for my DAC Index\n",
    "\n",
    "# Calculate centroids to center map\n",
    "centroids = gdf_subset.geometry.centroid\n",
    "\n",
    "# Convert centroids back to WGS84 (EPSG:4326)\n",
    "centroids = centroids.to_crs(epsg=4326)\n",
    "\n",
    "# Calculate the center for the map\n",
    "center_lat = centroids.y.mean()\n",
    "center_lon = centroids.x.mean()\n",
    "logger.info(f\"Center Latitude: {center_lat}, Center Longitude: {center_lon}\")\n",
    "\n",
    "#Converting to WGS84 to ensure proper coordinates\n",
    "gdf_subset = gdf_subset.to_crs(epsg=4326)  \n",
    "    \n",
    "# Convert the filtered GeoDataFrame to GeoJSON format\n",
    "geojson = json.loads(gdf_subset.to_json())\n",
    "\n",
    "# Create a DataFrame with the necessary columns\n",
    "data = gdf_subset[['ID', 'DAC_Ind']].copy()\n",
    "\n",
    "# Create the Plotly map\n",
    "fig = px.choropleth_mapbox(\n",
    "    data,\n",
    "    geojson=geojson,\n",
    "    locations='ID',\n",
    "    featureidkey=\"properties.ID\",  \n",
    "    color='DAC_Ind',\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    range_color=(data['DAC_Ind'].min(), data['DAC_Ind'].max()),\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "    zoom=10,  # Adjust the zoom level if necessary\n",
    "    opacity=0.5,\n",
    "    labels={'DAC_Ind': 'DAC Index'}\n",
    ")\n",
    "\n",
    "#Comment or delete everything below for final\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title=\"DAC Index for Selected Block Groups\",\n",
    "    margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "#fig.show()\n",
    "\n",
    "#Print nothing so jupyter notebook doesn't automatically generate a map since a fig.update was the last command\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd48f84-b126-4347-a642-84a8f2a136c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching the selected block group subset with the appropriate DOE/DOT subsets off their census tracts\n",
    "\n",
    "#Create an additional column on the gdf_subset which holds the First 9 digits of the block group ID\n",
    "gdf_subset['First 9'] = gdf_subset['ID'].astype(str).str[:9]\n",
    "logger.info(f'gdf_subset with first 9 digits of block group ID displayed in a column:\\n{gdf_subset.head()}')\n",
    "\n",
    "#Create an additional column in DOEDOT_gdf which holds the First 9 digits of the Census Tract GEOID\n",
    "DOEDOT_gdf['FIRST 9'] = DOEDOT_gdf['GEOID'].astype(str).str[:9]\n",
    "logger.info(f'DOEDOT_gdf with first 9 digits of census tract GEOID in column:\\n{DOEDOT_gdf.head()}')\n",
    "\n",
    "#Create empty list for DOEDOT subset\n",
    "DOEDOT_sub = []\n",
    "\n",
    "#Iterate over rows in DOEDOT_gdf to find where the first 9 digit of the ID and GEOID codes match and append those DOEDOT_gdf rows to the DOEDOT_sub list\n",
    "for index, row in DOEDOT_gdf.iterrows():\n",
    "    if row[\"FIRST 9\"] in gdf_subset['First 9'].values:\n",
    "        DOEDOT_sub.append(row)\n",
    "\n",
    "#Convert list back to GeoDataFrame\n",
    "DOEDOT_sub_gdf = gpd.GeoDataFrame(DOEDOT_sub, columns = DOEDOT_gdf.columns)\n",
    "\n",
    "logger.info(f'DOEDOT_sub_gdf:\\n{DOEDOT_sub_gdf.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b2bf6-b419-4957-8dda-67b5164926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addressing null/invalid geometries\n",
    "#Check for null geometries\n",
    "logger.info(f'Number of null geometries: {DOEDOT_sub_gdf['geometry'].isnull().sum()}')\n",
    "\n",
    "#Check for invalid geometries\n",
    "logger.info(f'Number of invalid geometries: {(~DOEDOT_sub_gdf.is_valid).sum()}')\n",
    "\n",
    "#Print invalid geometries\n",
    "invalid_geom = DOEDOT_sub_gdf[(~DOEDOT_sub_gdf.is_valid)]\n",
    "logger.info(f'GEOID(s) of invalid geometries: {invalid_geom['GEOID']}')\n",
    "\n",
    "#Remove any any null geometries and print information about it\n",
    "if DOEDOT_sub_gdf['geometry'].isnull().sum() > 0:\n",
    "    null_geom = DOEDOT_sub_gdf[DOEDOT_sub_gdf['geometry'].isnull()]\n",
    "    logger.info(f'GEOID(s) of null geometries: {null_geom['GEOID']}')\n",
    "    logger.info(f'Number of rows before removing null geometries: {len(DOEDOT_sub_gdf)}')\n",
    "    \n",
    "    #Remove rows with null geometries\n",
    "    DOEDOT_sub_gdf = DOEDOT_sub_gdf[DOEDOT_sub_gdf['geometry'].notnull()]\n",
    "    logger.info(f'Number of rows after removing null geometries: {len(DOEDOT_sub_gdf)}')\n",
    "    logger.info(f'Number of null geometries after removal: {DOEDOT_sub_gdf['geometry'].isnull().sum()}')\n",
    "    logger.info(f'Number of invalid geometries after removing null geometries: {(~DOEDOT_sub_gdf.is_valid).sum()}')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240fabf-49f4-4bd1-a3af-d4707907af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding DOE/DOT identified DAC layer to map\n",
    "\n",
    "#Seperate DOE/DOT data into two data sets that are identified DACs and not identified DACs\n",
    "NEVIDAC1 = DOEDOT_sub_gdf[DOEDOT_sub_gdf['NEVI_DAC'] == 1]\n",
    "NEVIDAC0 = DOEDOT_sub_gdf[DOEDOT_sub_gdf['NEVI_DAC'] == 0]\n",
    "\n",
    "#Convert to GeoJSON for graphing\n",
    "DOEDOT_geojson1 = json.loads(NEVIDAC1.to_json())\n",
    "DOEDOT_geojson0 = json.loads(NEVIDAC0.to_json())\n",
    "\n",
    "# Create a DataFrame with the necessary columns\n",
    "DOEDOT_data1 = NEVIDAC1[['GEOID', 'NEVI_DAC']].copy()\n",
    "DOEDOT_data0 = NEVIDAC0[['GEOID', 'NEVI_DAC']].copy()\n",
    "\n",
    "NEVI_DAC1_Layer = go.Choroplethmapbox(\n",
    "    geojson=DOEDOT_geojson1,\n",
    "    locations=NEVIDAC1['GEOID'],\n",
    "    featureidkey=\"properties.GEOID\",\n",
    "    z=NEVIDAC1['NEVI_DAC'],\n",
    "    colorscale=[(0, \"rgba(255, 255, 255, 0)\"), (1, \"rgba(255, 255, 255, 0)\")],  # Transparent color scale\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    "    marker_opacity=1,  # Adjust to make it as transparent as possible\n",
    "    marker_line_width=7,  # Default line width for NEVI_DAC == 0\n",
    "    showscale=False  # Hide the color scale bar for this layer\n",
    ")\n",
    "\n",
    "NEVI_DAC0_Layer = go.Choroplethmapbox(\n",
    "    geojson=DOEDOT_geojson0,\n",
    "    locations=NEVIDAC0['GEOID'],\n",
    "    featureidkey=\"properties.GEOID\",\n",
    "    z=NEVIDAC0['NEVI_DAC'],\n",
    "    colorscale=[(0, \"rgba(255, 255, 255, 0)\"), (1, \"rgba(255, 255, 255, 0)\")],  # Transparent color scale\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    "    marker_opacity=1,  # Adjust to make it as transparent as possible\n",
    "    marker_line_width=2,  # Default line width for NEVI_DAC == 0\n",
    "    showscale=False  # Hide the color scale bar for this layer\n",
    ")\n",
    "\n",
    "#Add these DOEDOT layers to the original figure\n",
    "fig.add_trace(NEVI_DAC1_Layer)\n",
    "fig.add_trace(NEVI_DAC0_Layer)\n",
    "\n",
    "# Re-order the data so orignal layer with DAC Index on top and hovers\n",
    "fig.data = (fig.data[2],fig.data[1],fig.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a070f04-a215-407f-9039-62876dbed7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that can graph all charging stations\n",
    "Charging_Sta_Layer = go.Scattermapbox(\n",
    "    lat=Sta_Lat,\n",
    "    lon=Sta_Lon,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color='red'\n",
    "    ),\n",
    "    name='Charging Stations'\n",
    ")\n",
    "\n",
    "#Add Charging Station Layer to figure\n",
    "fig.add_trace(Charging_Sta_Layer)\n",
    "\n",
    "#Updating map layout\n",
    "fig.update_layout(\n",
    "    title=\"Map of relative level of disadvantage around charging stations\",\n",
    "    margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0},\n",
    "    mapbox=dict(\n",
    "        style=\"open-street-map\",\n",
    "        center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "        zoom=10\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd1d07-553e-43c2-9a10-600906123c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Station_Type == \"PureHDV\":\n",
    "    print(\"IMPORTANT: More research is needed, especially the incorporation of STAKEHOLDER FEEDBACK THROUGH COMMUNITY ENGAGEMENT.\")\n",
    "    print(\"The assumed best locations for charging stations with only HDV ports intended for long haul transportation HDVs are in areas with the lowest DAC Index scores. Chargers should be strategically placed so truck routes naturally route around communities as best as possible, especially communities with higher DAC Index scores.\")\n",
    "elif Station_Type == \"MixedPorts\":\n",
    "    print(\"IMPORTANT: More research is needed, especially the incorporation of STAKEHOLDER FEEDBACK THROUGH COMMUNITY ENGAGEMENT.\")\n",
    "    print(\"The assumed best locations are on the fringe of areas with higher DAC Index scores. Chargers should be strategically placed so truck routes naturally route around communities while improving accessibility to LDV charging as best as possible, especially for communities with higher DAC Index scores.\")\n",
    "else:\n",
    "    print(\"Collect stakeholder feedback through community engagement to find the best locations to build desired EVSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8873f4-8fd9-4ecd-8f0e-33f4c052a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of code, below only need to be run if more information on where missing data for the entire datasets is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb1c33-0b75-48f4-ab97-18b46923d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of null values for each indicator used in the mean calculations. This does not need to be run and can be deleted if desired. Only for informative purposes\n",
    "\n",
    "# Economic Data (Econ_DA)\n",
    "print(\"Number of null P_LOWINCPCT:\", gdf['P_LOWINCPCT'].isnull().sum())\n",
    "print(\"Number of null P_UNEMPPCT:\", gdf['P_UNEMPPCT'].isnull().sum())\n",
    "\n",
    "# Social Data (Soc_DA)\n",
    "print(\"Number of null P_PEOPCOLORPCT:\", gdf['P_PEOPCOLORPCT'].isnull().sum())\n",
    "print(\"Number of null P_DISABILITYPCT:\", gdf['P_DISABILITYPCT'].isnull().sum())\n",
    "print(\"Number of null P_LINGISOPCT:\", gdf['P_LINGISOPCT'].isnull().sum())\n",
    "print(\"Number of null P_LESSHSPCT:\", gdf['P_LESSHSPCT'].isnull().sum())\n",
    "print(\"Number of null P_OVER64PCT:\", gdf['P_OVER64PCT'].isnull().sum())\n",
    "\n",
    "# Transportation Data (Transp_DA)\n",
    "print(\"Number of null P_PM25:\", gdf['P_PM25'].isnull().sum())\n",
    "print(\"Number of null P_OZONE:\", gdf['P_OZONE'].isnull().sum())\n",
    "print(\"Number of null P_DSLPM:\", gdf['P_DSLPM'].isnull().sum())\n",
    "print(\"Number of null P_RSEI_AIR:\", gdf['P_RSEI_AIR'].isnull().sum())\n",
    "print(\"Number of null P_PTRAF:\", gdf['P_PTRAF'].isnull().sum())\n",
    "print(\"Number of null P_NO2:\", gdf['P_NO2'].isnull().sum())\n",
    "\n",
    "# Environmental Data (Env_DA)\n",
    "print(\"Number of null P_LIFEEXPPCT:\", gdf['P_LIFEEXPPCT'].isnull().sum())\n",
    "print(\"Number of null P_LDPNT:\", gdf['P_LDPNT'].isnull().sum())\n",
    "print(\"Number of null P_PNPL:\", gdf['P_PNPL'].isnull().sum())\n",
    "print(\"Number of null P_PRMP:\", gdf['P_PRMP'].isnull().sum())\n",
    "print(\"Number of null P_PTSDF:\", gdf['P_PTSDF'].isnull().sum())\n",
    "print(\"Number of null P_UST:\", gdf['P_UST'].isnull().sum())\n",
    "print(\"Number of null P_PWDIS:\", gdf['P_PWDIS'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7725c-be04-4895-affd-c06239c3cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing null/invalid geometries for entire DOEDOT gdf. Not necessarry to run\n",
    "#Check for null geometries\n",
    "print(\"Number of null geometries:\", DOEDOT_gdf['geometry'].isnull().sum())\n",
    "\n",
    "#Check for invalid geometries\n",
    "print(\"Number of invalid geometries:\", (~DOEDOT_gdf.is_valid).sum())\n",
    "\n",
    "print(len(DOEDOT_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e88dc9-5db1-46b4-af44-2b4cb781d0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
